data  = {
    "SAP Developer":
    ["Yes, you can run a business warehouse without R/3 implementation. You have to simply transfer structures associated with business warehouse data sources (ODS table, Infocube) to the inbound data files or use third-party tools to connect your flat files and other data sources.Different layers in the R/3 system includes Presentation Layer Database layer Application layer",
    "To create a table in the data dictionary, you have to follow this step.Creating domains (data type, field length, range) . Creating data elements (properties and type for a table field) . Creating tables (SE 11)",
   "The SAP smart forms tool is an excellent way to send and print important documents. I use this tool to create forms, emails, PDF files and documents that I plan to share with clients and coworkers online because it makes it easy to create the layout and maintain the logic of forms. It also allows me to make quick updates by using graphical tools instead of having to program changes manually. If I'm collaborating on a project with someone who isn't familiar with programming, this is especially important because the SAP smart tools allow them to enter data easily.There are also several form templates the SAP smart tools provide to streamline processes for sales and distribution (SD), customer relationship management (CRM), human resources (HR) and financial accounting."],

   "DotNet Developer":[
       "Yes, Both Encapsulation and Abstraction do the same thing but with few differences Encapsulation mainly encapsulates the object and so hides the details as well as it binds the data.So Encapsulation = Hiding + Binding the data ",
       "When the Garbage Collector gets called by the CLR to DE-allocate the memory in the heap, the Garbage Collector start finding the references of all the reachable objects which are currently in use. So it find the objects which are used by the processes and for rest of objects which are un-reachable or the Garbage collector is not able to find the references for them, it marks them for deletion.    Here the Garbage collector makes an Object graph which keeps track of all the objects which are marked for deletion. After the deleting the references for those objects, the heap memory gets compacted and a new root becomes available to use by the new created object. No, this object graph creates virtually by the Garbage Collector to keep all the objects and to make them for deletion. This is the Garbage Collector responsibility to create this object graph and gets the references of each reachable object which are used by the application",
       "The main difference between IIS and Kestrel is that Kestrel is a cross-platform server. It runs on Windows, Linux, and Mac, whereas IIS only runs on Windows.Another essential difference between the two is that Kestrel is fully open-source, whereas IIS is closed-source and developed and maintained only by Microsoft.IIS is very old software and comes with a considerable legacy and bloat. With Kestrel, Microsoft started with high-performance in mind. They developed it from scratch, which allowed them to ignore the legacy/compatibility issues and focus on speed and efficiency.However, Kestrel doesn’t provide all the rich functionality of a full-fledged web server such as IIS, Nginx, or Apache. Hence, we typically use it as an application server, with one of the above servers acting as a reverse proxy. "
   ],
   "Data Science":[
       'Time series data is known to posses linearity. On the other hand, a decision tree algorithm is known to work best to detect non – linear interactions. The reason why decision tree failed to provide robust predictions because it couldn’t map the linear relationship as good as a regression model did. Therefore, we learned that, a linear regression model can provide robust prediction given the data set satisfies its linearity assumptions.',
       'Low bias occurs when the model’s predicted values are near to actual values. In other words, the model becomes flexible enough to mimic the training data distribution. While it sounds like great achievement, but not to forget, a flexible model has no generalization capabilities. It means, when this model is tested on an unseen data, it gives disappointing results.In such situations, we can use bagging algorithm (like random forest) to tackle high variance problem. Bagging algorithms divides a data set into subsets made with repeated randomized sampling. Then, these samples are used to generate  a set of models using a single learning algorithm. Later, the model predictions are combined using voting (classification) or averaging (regression).Also, to combat high variance, we can Use regularization technique, where higher model coefficients get penalized, hence lowering model complexity. Use top n features from variable importance chart. May be, with all the variable in the data set, the algorithm is having difficulty in finding the meaningful signal.',
       'As we know, ensemble learners are based on the idea of combining weak learners to create strong learners. But, these learners provide superior results when the combined models are uncorrelated. Since, we have used 5 GBM models and got no accuracy improvement, suggests that the models are correlated. The problem with correlated models is, all the models provide same information.For example: If model 1 has classified User1122 as 1, there are high chances model 2 and model 3 would have done the same, even if its actual value is 0. Therefore, ensemble learners are built on the premise of combining weak uncorrelated models to obtain better predictions.'
   ]
}